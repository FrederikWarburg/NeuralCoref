{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.getcwd()\n",
    "ROOT_PATH = os.path.abspath(os.path.join(DIR_PATH, os.pardir))\n",
    "DATA_ROOT = os.path.join(ROOT_PATH, 'data')\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap')\n",
    "SUB_DATA_FOLDER = os.path.join(DATA_ROOT, 'gendered-pronoun-resolution')\n",
    "#FAST_TEXT_DATA_FOLDER = os.path.join(DATA_ROOT, 'fasttext-crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isak\\NeuralCoref\\data\n"
     ]
    }
   ],
   "source": [
    "print(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-development.tsv')\n",
    "train_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-test.tsv')\n",
    "dev_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-validation.tsv')\n",
    "\n",
    "train_df = pd.read_csv(train_df_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_df_path, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_df_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun  \\\n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her   \n",
       "1  development-2  He grew up in Evanston, Illinois the second ol...     His   \n",
       "2  development-3  He had been reelected to Congress, but resigne...     his   \n",
       "3  development-4  The current members of Crime have also perform...     his   \n",
       "4  development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...     She   \n",
       "\n",
       "   Pronoun-offset                  A  A-offset  A-coref                B  \\\n",
       "0             274     Cheryl Cassidy       191     True          Pauline   \n",
       "1             284          MacKenzie       228     True    Bernard Leach   \n",
       "2             265            Angeloz       173    False       De la Sota   \n",
       "3             321               Hell       174    False  Henry Rosenthal   \n",
       "4             437  Kitty Oppenheimer       219    False           Rivera   \n",
       "\n",
       "   B-offset  B-coref                                                URL  \n",
       "0       207    False  http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1       251    False      http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2       246     True  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3       336     True          http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4       294     True        http://en.wikipedia.org/wiki/Jessica_Rivera  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import DependencyParser\n",
    "import spacy\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = \"en_core_web_lg\"\n",
    "nlp = spacy.load(spacy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize_term(term, pos):\n",
    "    male_PRON = [\"He\", \"Him\", \"he\", \"him\", \"himself\"]\n",
    "    female_PRON = [\"She\", \"Her\", \"she\", \"her\", \"herself\"]\n",
    "    neutral_PRON = [\"It\", \"It\", \"it\", \"it\", \"itself\"]\n",
    "    male_DET = [\"His\", \"his\"]\n",
    "    female_DET = [\"Her\", \"her\"]\n",
    "    neutral_DET = [\"Its\", \"its\"]\n",
    "    \n",
    "    replace = False\n",
    "    \n",
    "    if pos == \"PRON\" and term in male_PRON:\n",
    "        replace = True\n",
    "    elif pos == \"PRON\" and term in female_PRON:\n",
    "        replace = True               \n",
    "    elif pos == \"DET\" and term in male_DET:\n",
    "        replace = True               \n",
    "    elif pos == \"DET\" and term in female_DET:\n",
    "        replace = True               \n",
    "    else:\n",
    "        return term\n",
    "    \n",
    "    if replace:       \n",
    "        if pos == \"PRON\":\n",
    "            if term in male_PRON:\n",
    "                index = male_PRON.index(term)\n",
    "            elif term in female_PRON:\n",
    "                index = female_PRON.index(term)\n",
    "            neutral_term = neutral_PRON[index]\n",
    "\n",
    "        elif pos == \"DET\":\n",
    "            if term in male_DET:\n",
    "                index = male_DET.index(term)\n",
    "            elif term in female_DET:\n",
    "                index = female_DET.index(term)\n",
    "            neutral_term = neutral_DET[index]\n",
    "    return neutral_term   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [r\".\", r\",\", r\":\", r\";\", r\"?\", r\"!\", r\"'s\"]\n",
    "\n",
    "def alter_dataframe(df):\n",
    "    for row_idx in range(len(df)):\n",
    "        text = df.loc[row_idx, \"Text\"]\n",
    "        offsets = [df.loc[row_idx, \"Pronoun-offset\"], df.loc[row_idx, \"A-offset\"], df.loc[row_idx, \"B-offset\"]]\n",
    "        new_text, new_offsets = neutralize_and_update(text, nlp(text), offsets)\n",
    "        df.loc[row_idx, \"Text\"] = new_text\n",
    "        df.loc[row_idx, \"Pronoun-offset\"] = offsets[0]\n",
    "        df.loc[row_idx, \"A-offset\"] = offsets[1]\n",
    "        df.loc[row_idx, \"B-offset\"] = offsets[2]\n",
    "        df.loc[row_idx, \"Pronoun\"] = find_pronoun(new_text, df.loc[row_idx, \"Pronoun-offset\"])\n",
    "        if not row_idx % 50:\n",
    "            print(\"Progress: %i / %i documents\" % (row_idx, len(df)))\n",
    "    return df\n",
    "\n",
    "def find_pronoun(text, offset):\n",
    "    punctuation = [r\".\", r\",\", r\":\", r\";\", r\"?\", r\"!\", r\"'s\", r\"n't\"]\n",
    "    index = offset\n",
    "    character = text[index]\n",
    "    pronoun = \"\"\n",
    "    while character not in punctuation and character != \" \":\n",
    "        pronoun += character\n",
    "        index += 1\n",
    "        character = text[index]\n",
    "    return pronoun\n",
    "\n",
    "def neutralize_and_update(text, processed_text, offsets):\n",
    "    all_gender_prons = [\"he\", \"him\", \"himself\", \"she\", \"her\", \"herself\", \"his\", \"her\"]\n",
    "    char_count = 0\n",
    "    first = True\n",
    "    new_text = \"\"\n",
    "    \n",
    "    num_pronouns_before = []\n",
    "    for entity in range(3):\n",
    "        offset = offsets[entity]\n",
    "        substring = nlp(text[0:offset])\n",
    "        pron_count = 0\n",
    "        for token in substring:\n",
    "            if token.lower_ in all_gender_prons:\n",
    "                pron_count += 1\n",
    "        num_pronouns_before.append(pron_count)\n",
    "    \n",
    "    modifications = []\n",
    "    for token in processed_text:\n",
    "        #print(token.text, token.pos_)\n",
    "        new_token = neutralize_term(token.text, token.pos_)\n",
    "        if new_token != token.text:            \n",
    "            diff = len(new_token) - len(token)\n",
    "            modifications.append(diff)\n",
    "                     \n",
    "        if (token.text not in punctuation) and not first:\n",
    "            new_text += r\" \"\n",
    "        first = False\n",
    "        new_text += new_token\n",
    "            \n",
    "    #print(\"Length modifications:\", modifications)\n",
    "    #print(\"Number of preceeding pronouns:\", num_pronouns_before)\n",
    "    for idx, offset in enumerate(offsets):\n",
    "        for mod in range(num_pronouns_before[idx]):\n",
    "            offset += modifications[mod]\n",
    "        offsets[idx] = offset\n",
    "                \n",
    "    return new_text, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_from_offset(text, offset):\n",
    "    \n",
    "    for token in spans(text):\n",
    "        \n",
    "        if offset == token[2]:\n",
    "            return token[0]\n",
    "\n",
    "def spans(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    offset = 0\n",
    "    for token_count, token in enumerate(doc):\n",
    "        token = str(token)\n",
    "        #for token_count, token in enumerate(tokens):\n",
    "        offset = text.find(token, offset)\n",
    "        yield token_count, token, offset, offset+len(token)\n",
    "        offset += len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                    validation-11\n",
       "Text              This particular government recalled all the Gr...\n",
       "Pronoun                                                          he\n",
       "Pronoun-offset                                                  418\n",
       "A                                                  Ioannis Mamouris\n",
       "A-offset                                                        273\n",
       "A-coref                                                       False\n",
       "B                                                         Kallergis\n",
       "B-offset                                                        435\n",
       "B-coref                                                        True\n",
       "URL                http://en.wikipedia.org/wiki/Dimitrios_Kallergis\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = 10\n",
    "text = dev_df.loc[row, \"Text\"]\n",
    "pronoun_offset = dev_df.loc[row, \"Pronoun-offset\"]\n",
    "dev_df.loc[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n"
     ]
    }
   ],
   "source": [
    "span = get_span_from_offset(text, pronoun_offset)\n",
    "processed_text = nlp(text)\n",
    "print(processed_text[span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [r\".\", r\",\", r\":\", r\";\", r\"?\", r\"!\", r\"'s\"]\n",
    "\n",
    "def compare_pronouns(corpus_df, num_docs):\n",
    "    for row in range(num_docs):\n",
    "        text = corpus_df.loc[row, \"Text\"]\n",
    "        correct_pronoun = corpus_df.loc[row, \"Pronoun\"]\n",
    "        pronoun = \"\"\n",
    "        start = corpus_df.loc[row, \"Pronoun-offset\"]\n",
    "\n",
    "        index = start\n",
    "        character = text[start]\n",
    "        while character not in punctuation and character != \" \":\n",
    "            pronoun += character\n",
    "            index += 1\n",
    "            character = text[index]\n",
    "        print(\"Correct pronoun:\", correct_pronoun, \", and in text:\", pronoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0 / 454 documents\n",
      "Progress: 50 / 454 documents\n",
      "Progress: 100 / 454 documents\n",
      "Progress: 150 / 454 documents\n",
      "Progress: 200 / 454 documents\n",
      "Progress: 250 / 454 documents\n",
      "Progress: 300 / 454 documents\n",
      "Progress: 350 / 454 documents\n",
      "Progress: 400 / 454 documents\n",
      "Progress: 450 / 454 documents\n"
     ]
    }
   ],
   "source": [
    "#test_ntr_df = test_df.copy()\n",
    "dev_ntr_df = alter_dataframe(dev_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This This\n",
      "particular particular\n",
      "government government\n",
      "recalled recalled\n",
      "all all\n",
      "the the\n",
      "Greek Greek\n",
      "officers officers\n",
      "who who\n",
      "participated participated\n",
      "in in\n",
      "the the\n",
      "anti anti\n",
      "- -\n",
      "Ottoman Ottoman\n",
      "revolutionary revolutionary\n",
      "movements movements\n",
      "in in\n",
      "Thessaly Thessaly\n",
      ", ,\n",
      "Epirus Epirus\n",
      "and and\n",
      "Macedonia Macedonia\n",
      "to to\n",
      "return return\n",
      "to to\n",
      "Greece Greece\n",
      "while while\n",
      "by by\n",
      "personal personal\n",
      "requirement requirement\n",
      "of of\n",
      "Kallergis Kallergis\n",
      ", ,\n",
      "Otto Otto\n",
      "'s 's\n",
      "adjutants-- adjutants--\n",
      "Gennaios Gennaios\n",
      "Kolokotronis Kolokotronis\n",
      ", ,\n",
      "Spyromilios Spyromilios\n",
      ", ,\n",
      "Ioannis Ioannis\n",
      "Mamouris Mamouris\n",
      "and and\n",
      "Gardikiotis Gardikiotis\n",
      "Grivas Grivas\n",
      "-- --\n",
      "were were\n",
      "dismissed dismissed\n",
      ", ,\n",
      "while while\n",
      "the the\n",
      "hitherto hitherto\n",
      "Minister Minister\n",
      "of of\n",
      "Military Military\n",
      "Affairs Affairs\n",
      ", ,\n",
      "Skarlatos Skarlatos\n",
      "Soutsos Soutsos\n",
      ", ,\n",
      "was was\n",
      "suspended suspended\n",
      ". .\n",
      "When When\n",
      "he it\n",
      "was was\n",
      "minister minister\n",
      ", ,\n",
      "Kallergis Kallergis\n",
      "formed formed\n",
      "for for\n",
      "the the\n",
      "first first\n",
      "time time\n",
      "in in\n",
      "Greece Greece\n",
      "a a\n",
      "fire fire\n",
      "brigade brigade\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "row = 10\n",
    "text = nlp(dev_df.loc[row, \"Text\"])\n",
    "ntr_text = nlp(dev_ntr_df.loc[row, \"Text\"])\n",
    "for word in range(len(text)):\n",
    "    print(text[word], ntr_text[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No amount of logic can shatter a faith consciously based on a lie.'' According to The Skeptic's Dictionary, an example of this syndrome is evidenced by an event in 1988 when stage magician James Randi, at the request of an Australian news program, coached stage performer Jos* Alvarez to pretend he was channelling a two-thousand-year-old spirit named ``Carlos''.\n",
      "No amount of logic can shatter a faith consciously based on a lie. ' ' According to The Skeptic's Dictionary, an example of this syndrome is evidenced by an event in 1988 when stage magician James Randi, at the request of an Australian news program, coached stage performer Jos * Alvarez to pretend it was channelling a two - thousand - year - old spirit named ` ` Carlos ' '.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation-1</td>\n",
       "      <td>It admitted making four trips to China and pla...</td>\n",
       "      <td>it</td>\n",
       "      <td>256</td>\n",
       "      <td>Jose de Venecia Jr</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>Abalos</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation-2</td>\n",
       "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
       "      <td>It</td>\n",
       "      <td>185</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation-3</td>\n",
       "      <td>When it returns to its hotel room, a Liberian ...</td>\n",
       "      <td>ring</td>\n",
       "      <td>431</td>\n",
       "      <td>Jason Scott Lee</td>\n",
       "      <td>379</td>\n",
       "      <td>False</td>\n",
       "      <td>Danny</td>\n",
       "      <td>402</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validation-4</td>\n",
       "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
       "      <td>it</td>\n",
       "      <td>333</td>\n",
       "      <td>Reucassel</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>Debnam</td>\n",
       "      <td>325</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Craig_Reucassel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation-5</td>\n",
       "      <td>By this time, Karen Blixen had separated from ...</td>\n",
       "      <td></td>\n",
       "      <td>427</td>\n",
       "      <td>Finch Hatton</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>Beryl Markham</td>\n",
       "      <td>328</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Denys_Finch_Hatton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Pronoun  \\\n",
       "0  validation-1  It admitted making four trips to China and pla...      it   \n",
       "1  validation-2  Kathleen Nott was born in Camberwell, London. ...      It   \n",
       "2  validation-3  When it returns to its hotel room, a Liberian ...    ring   \n",
       "3  validation-4  On 19 March 2007, during a campaign appearance...      it   \n",
       "4  validation-5  By this time, Karen Blixen had separated from ...           \n",
       "\n",
       "   Pronoun-offset                   A  A-offset  A-coref              B  \\\n",
       "0             256  Jose de Venecia Jr       208    False         Abalos   \n",
       "1             185               Ellen       110    False       Kathleen   \n",
       "2             431     Jason Scott Lee       379    False          Danny   \n",
       "3             333           Reucassel       300     True         Debnam   \n",
       "4             427        Finch Hatton       290    False  Beryl Markham   \n",
       "\n",
       "   B-offset  B-coref                                                URL  \n",
       "0       241    False  http://en.wikipedia.org/wiki/Commission_on_Ele...  \n",
       "1       150     True         http://en.wikipedia.org/wiki/Kathleen_Nott  \n",
       "2       402     True  http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...  \n",
       "3       325    False       http://en.wikipedia.org/wiki/Craig_Reucassel  \n",
       "4       328     True    http://en.wikipedia.org/wiki/Denys_Finch_Hatton  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = 5\n",
    "print(dev_df.loc[row, \"Text\"])\n",
    "print(dev_ntr_df.loc[row, \"Text\"])\n",
    "dev_ntr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_pronoun(dev_df.loc[4, \"Text\"], dev_df.loc[4, \"Pronoun-offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pronoun: it , and in text: it\n",
      "Correct pronoun: It , and in text: It\n",
      "Correct pronoun: ring , and in text: ring\n",
      "Correct pronoun: it , and in text: it\n",
      "Correct pronoun:  , and in text: \n",
      "Correct pronoun: nd , and in text: nd\n",
      "Correct pronoun: ng , and in text: ng\n",
      "Correct pronoun: its , and in text: its\n",
      "Correct pronoun: wan , and in text: wan\n",
      "Correct pronoun: hat , and in text: hat\n"
     ]
    }
   ],
   "source": [
    "compare_pronouns(dev_ntr_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_df(df, row_idx):\n",
    "    text = df.loc[row_idx, \"Text\"]\n",
    "    pronoun = df.loc[row_idx, \"Pronoun\"]\n",
    "    pronoun_offset = df.loc[row_idx, \"Pronoun-offset\"]\n",
    "    pronoun_in_text = find_pronoun(text, pronoun_offset)\n",
    "    print(text, \"\\n\", pronoun, pronoun_offset, pronoun_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She auditions to be a dancer at Cheung Lai Yuen for a better income and a chance to find her father, who is the Emperor. Evergreen Mak as Ko Yan (**) / Kiu Bo-lung (***), a Music Bureau official who looks over Cheung Lai Yuen. In a quarrel with Ming-but, Bo-lung loses his memory and gets half of his face burnt. \n",
      " his 269 his\n"
     ]
    }
   ],
   "source": [
    "test_df(test_ntr_df, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_a = \"My name is Isak and I am a happy boy.\"\n",
    "text = nlp(string_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.doc.Doc' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-e59cef20f190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Frederik\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "text[3] = \"Frederik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
