{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.getcwd()\n",
    "ROOT_PATH = os.path.abspath(os.path.join(DIR_PATH, os.pardir))\n",
    "DATA_ROOT = os.path.join(ROOT_PATH, 'data')\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap')\n",
    "SUB_DATA_FOLDER = os.path.join(DATA_ROOT, 'gendered-pronoun-resolution')\n",
    "#FAST_TEXT_DATA_FOLDER = os.path.join(DATA_ROOT, 'fasttext-crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isak\\NeuralCoref\\data\n"
     ]
    }
   ],
   "source": [
    "print(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-development.tsv')\n",
    "train_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-test.tsv')\n",
    "dev_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-validation.tsv')\n",
    "\n",
    "train_df = pd.read_csv(train_df_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_df_path, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_df_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun  \\\n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her   \n",
       "1  development-2  He grew up in Evanston, Illinois the second ol...     His   \n",
       "2  development-3  He had been reelected to Congress, but resigne...     his   \n",
       "3  development-4  The current members of Crime have also perform...     his   \n",
       "4  development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...     She   \n",
       "\n",
       "   Pronoun-offset                  A  A-offset  A-coref                B  \\\n",
       "0             274     Cheryl Cassidy       191     True          Pauline   \n",
       "1             284          MacKenzie       228     True    Bernard Leach   \n",
       "2             265            Angeloz       173    False       De la Sota   \n",
       "3             321               Hell       174    False  Henry Rosenthal   \n",
       "4             437  Kitty Oppenheimer       219    False           Rivera   \n",
       "\n",
       "   B-offset  B-coref                                                URL  \n",
       "0       207    False  http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1       251    False      http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2       246     True  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3       336     True          http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4       294     True        http://en.wikipedia.org/wiki/Jessica_Rivera  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pronoun: him , and in text: him\n",
      "Correct pronoun: She , and in text: She\n",
      "Correct pronoun: his , and in text: his\n",
      "Correct pronoun: he , and in text: he\n",
      "Correct pronoun: she , and in text: she\n",
      "Correct pronoun: he , and in text: he\n",
      "Correct pronoun: He , and in text: He\n",
      "Correct pronoun: his , and in text: his\n",
      "Correct pronoun: he , and in text: he\n",
      "Correct pronoun: her , and in text: her\n"
     ]
    }
   ],
   "source": [
    "punctuation = [r\".\", r\",\", r\":\", r\";\", r\"?\", r\"!\", r\"'s\"]\n",
    "\n",
    "def compare_pronouns(corpus_df, num_docs):\n",
    "    for row in range(num_docs):\n",
    "        text = corpus_df.loc[row, \"Text\"]\n",
    "        correct_pronoun = corpus_df.loc[row, \"Pronoun\"]\n",
    "        pronoun = \"\"\n",
    "        start = corpus_df.loc[row, \"Pronoun-offset\"]\n",
    "\n",
    "        index = start\n",
    "        character = text[start]\n",
    "        while character not in punctuation and character != \" \":\n",
    "            pronoun += character\n",
    "            index += 1\n",
    "            character = text[index]\n",
    "        print(\"Correct pronoun:\", correct_pronoun, \", and in text:\", pronoun)\n",
    "    \n",
    "compare_pronouns(dev_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = [doc for doc in train_df.loc[:, \"Text\"]]\n",
    "dev_docs = [doc for doc in dev_df.loc[:, \"Text\"]]\n",
    "test_docs = [doc for doc in test_df.loc[:, \"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import DependencyParser\n",
    "import spacy\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = \"en_core_web_lg\"\n",
    "nlp = spacy.load(spacy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(documents):\n",
    "    processed_docs = []\n",
    "    for document in documents:\n",
    "        doc = nlp(document)\n",
    "        processed_docs.append(doc)\n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prcd = process_docs(train_docs) # Should take about 1 min 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_prcd = process_docs(dev_docs) # Takes about 15 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prcd = process_docs(test_docs) # Takes about 1 min 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 2000\n",
      "<class 'list'> 454\n",
      "<class 'list'> 2000\n"
     ]
    }
   ],
   "source": [
    "print(type(train_prcd), len(train_prcd))\n",
    "print(type(dev_prcd), len(dev_prcd))\n",
    "print(type(test_prcd), len(test_prcd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_PRON = [\"He\", \"Him\", \"he\", \"him\"]\n",
    "female_PRON = [\"She\", \"Her\", \"she\", \"her\"]\n",
    "neutral_PRON = [\"They\", \"Them\", \"they\", \"them\"]\n",
    "male_DET = [\"His\", \"his\"]\n",
    "female_DET = [\"Her\", \"her\"]\n",
    "neutral_DET = [\"Their\", \"their\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neutral_term(term, pos):\n",
    "    male_PRON = [\"He\", \"Him\", \"he\", \"him\"]\n",
    "    female_PRON = [\"She\", \"Her\", \"she\", \"her\"]\n",
    "    neutral_PRON = [\"They\", \"Them\", \"they\", \"them\"]\n",
    "    male_DET = [\"His\", \"his\"]\n",
    "    female_DET = [\"Her\", \"her\"]\n",
    "    neutral_DET = [\"Their\", \"their\"]\n",
    "    \n",
    "    if pos == \"PRON\":\n",
    "        if term in male_PRON:\n",
    "            index = male_PRON.index(term)\n",
    "        elif term in female_PRON:\n",
    "            index = female_PRON.index(term)\n",
    "        neutral_term = neutral_PRON[index]\n",
    "        \n",
    "    elif pos == \"DET\":\n",
    "        if term in male_DET:\n",
    "            index = male_DET.index(term)\n",
    "        elif term in female_DET:\n",
    "            index = female_DET.index(term)\n",
    "        neutral_term = neutral_DET[index]\n",
    "    return neutral_term\n",
    "    \n",
    "\n",
    "def produce_neutral_text(processed_docs):\n",
    "    new_docs = []    \n",
    "    for doc in processed_docs:\n",
    "        new_doc = []\n",
    "        for token in doc:\n",
    "            # print(token.text, token.pos_)\n",
    "            if token.pos_ == \"PRON\" and token.text in male_PRON:\n",
    "                new_token = find_neutral_term(token.text, \"PRON\")\n",
    "            elif token.pos_ == \"PRON\" and token.text in female_PRON:\n",
    "                new_token = find_neutral_term(token.text, \"PRON\")                   \n",
    "            elif token.pos_ == \"DET\" and token.text in male_DET:\n",
    "                new_token = find_neutral_term(token.text, \"DET\")\n",
    "            elif token.pos_ == \"DET\" and token.text in female_DET:\n",
    "                new_token = find_neutral_term(token.text, \"DET\")\n",
    "            else:\n",
    "                new_token = token.text\n",
    "            new_doc.append(new_token)\n",
    "        new_docs.append(new_doc)\n",
    "    return new_docs\n",
    "\n",
    "punctuation = [r\".\", r\",\", r\":\", r\";\", r\"?\", r\"!\", r\"'s\"]\n",
    "\n",
    "def to_pure_text(corpus):\n",
    "    corpus_text = []\n",
    "    for doc_id, document in enumerate(corpus):\n",
    "        first = True\n",
    "        # Produce all text from document into a single line\n",
    "        text = ''\n",
    "        for token in document:\n",
    "            if (token not in punctuation) and not first:\n",
    "                text += r\" \"\n",
    "            first = False\n",
    "            text += token\n",
    "        corpus_text.append(text)\n",
    "    return corpus_text        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They admitted making four trips to China and playing golf there. They also admitted that ZTE officials, whom they says are their golf buddies, hosted and paid for the trips. Jose de Venecia III, son of House Speaker Jose de Venecia Jr, alleged that Abalos offered them US$ 10 million to withdraw their proposal on the NBN project.\n",
      "He admitted making four trips to China and playing golf there. He also admitted that ZTE officials, whom he says are his golf buddies, hosted and paid for the trips. Jose de Venecia III, son of House Speaker Jose de Venecia Jr, alleged that Abalos offered him US$10 million to withdraw his proposal on the NBN project.\n"
     ]
    }
   ],
   "source": [
    "dev_ntr = produce_neutral_text(dev_prcd)\n",
    "dev_ntr_text = to_pure_text(dev_ntr)\n",
    "print(dev_ntr_text[0])\n",
    "print(dev_df.loc[0, \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pronoun: him , and in text: offered\n",
      "Correct pronoun: She , and in text: er\n",
      "Correct pronoun: his , and in text: \n",
      "Correct pronoun: he , and in text: they\n",
      "Correct pronoun: she , and in text: \n",
      "Correct pronoun: he , and in text: nd\n",
      "Correct pronoun: He , and in text: ht\n",
      "Correct pronoun: his , and in text: omote\n",
      "Correct pronoun: he , and in text: Cowan\n",
      "Correct pronoun: her , and in text: or\n"
     ]
    }
   ],
   "source": [
    "dev_ntr_df = dev_df.copy()\n",
    "dev_ntr_df.head()\n",
    "\n",
    "for row_idx in range(len(dev_ntr_df)):\n",
    "    dev_ntr_df.loc[row_idx, \"Text\"] = dev_ntr_text[row_idx]\n",
    "    \n",
    "dev_ntr_df.head()\n",
    "compare_pronouns(dev_ntr_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_neutral_list(document):\n",
    "    new_doc = []\n",
    "    for token in document:\n",
    "        # print(token.text, token.pos_)\n",
    "        if token.pos_ == \"PRON\" and token.text in male_PRON:\n",
    "            new_token = find_neutral_term(token.text, \"PRON\")\n",
    "        elif token.pos_ == \"PRON\" and token.text in female_PRON:\n",
    "            new_token = find_neutral_term(token.text, \"PRON\")                   \n",
    "        elif token.pos_ == \"DET\" and token.text in male_DET:\n",
    "            new_token = find_neutral_term(token.text, \"DET\")\n",
    "        elif token.pos_ == \"DET\" and token.text in female_DET:\n",
    "            new_token = find_neutral_term(token.text, \"DET\")\n",
    "        else:\n",
    "            new_token = token.text\n",
    "        new_doc.append(new_token)\n",
    "    return new_doc\n",
    "\n",
    "punctuation = [r\".\", r\",\", r\":\", r\";\", r\"?\", r\"!\", r\"'s\"]\n",
    "\n",
    "def document_to_pure_text(document):\n",
    "    first = True\n",
    "    # Produce all text from document into a single line\n",
    "    text = ''\n",
    "    for token in document:\n",
    "        if (token not in punctuation) and not first:\n",
    "            text += r\" \"\n",
    "        first = False\n",
    "        text += token\n",
    "    return text      \n",
    "\n",
    "def alter_dataframe(dataframe):\n",
    "    punctuation = [r\".\", r\",\", r\":\", r\";\", r\"?\", r\"!\", r\"'s\"]\n",
    "    \n",
    "    entities = [\"Pronoun\", \"A\", \"B\"]\n",
    "    entity_offsets = [\"Pronoun-offset\", \"A-offset\", \"B-offset\"]\n",
    "    \n",
    "    for row_idx in range(len(dataframe)):\n",
    "        text = dataframe.loc[row_idx, \"Text\"]        \n",
    "        text_prcd = nlp(text)\n",
    "        sent = word_tokenize(text)\n",
    "        neutral_list = document_to_neutral_list(text_prcd)\n",
    "        neutral_text = document_to_pure_text(neutral_list)\n",
    "        neutral_sent = word_tokenize(neutral_text)\n",
    "        \n",
    "        for entity_idx, entity in enumerate(entities):\n",
    "            mention = dataframe.loc[row_idx, entity]\n",
    "            offset = dataframe.loc[row_idx, entity_offsets[entity_idx]]\n",
    "            word_idx = word_idx_from_char_offset(text, offset)\n",
    "            if entity == \"Pronoun\":\n",
    "                pronoun = dataframe.loc[row_idx, \"Pronoun\"]\n",
    "                new_pronoun = neutral_sent[word_idx]\n",
    "                dataframe.loc[row_idx, \"Pronoun\"] = new_pronoun\n",
    "                #print(\"Kvekk\", pronoun, new_pronoun)\n",
    "                mention = new_pronoun\n",
    "            dataframe.loc[row_idx, entity_offsets[entity_idx]] = new_char_offset(neutral_text, offset, mention)\n",
    "        \n",
    "        dataframe.loc[row_idx, \"Text\"] = neutral_text\n",
    "        if not row_idx % 1:\n",
    "            print(\"Progress: %i / %i documents\" % (row_idx, len(dataframe)))\n",
    "        \n",
    "    return dataframe\n",
    "            \n",
    "def new_char_offset(text, offset, mention):\n",
    "    left_start = offset\n",
    "    right_start = offset\n",
    "    left = True\n",
    "    right = False\n",
    "    index = -1\n",
    "    \n",
    "    while index == -1:\n",
    "        if left:\n",
    "            index = text.find(mention, left_start)\n",
    "            left_start -= 1\n",
    "            left = False\n",
    "        else:\n",
    "            index = text.find(mention, right_start)\n",
    "            right_start += 1\n",
    "            left = True\n",
    "    # print(mention)\n",
    "    return index\n",
    "    \n",
    "    \n",
    "def word_idx_from_char_offset(text, offset):\n",
    "    entity = \"\"\n",
    "    substring = text[:offset]\n",
    "    substring_tokens = word_tokenize(substring)\n",
    "    return len(substring_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0 / 454 documents\n",
      "Progress: 1 / 454 documents\n",
      "Progress: 2 / 454 documents\n",
      "Progress: 3 / 454 documents\n",
      "Progress: 4 / 454 documents\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-0a5c6174990b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdev_ntr_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdev_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdev_ntr_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malter_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_ntr_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-016d32f2d9f2>\u001b[0m in \u001b[0;36malter_dataframe\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;31m#print(\"Kvekk\", pronoun, new_pronoun)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0mmention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_pronoun\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_offsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentity_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_char_offset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneutral_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneutral_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-016d32f2d9f2>\u001b[0m in \u001b[0;36mnew_char_offset\u001b[1;34m(text, offset, mention)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mright_start\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;31m# print(mention)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev_ntr_df = dev_df.copy()\n",
    "dev_ntr_df = alter_dataframe(dev_ntr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation-1</td>\n",
       "      <td>He admitted making four trips to China and pla...</td>\n",
       "      <td>them</td>\n",
       "      <td>-1</td>\n",
       "      <td>Jose de Venecia Jr</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>Abalos</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation-2</td>\n",
       "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
       "      <td>They</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation-3</td>\n",
       "      <td>When she returns to her hotel room, a Liberian...</td>\n",
       "      <td>their</td>\n",
       "      <td>-1</td>\n",
       "      <td>Jason Scott Lee</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>Danny</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validation-4</td>\n",
       "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
       "      <td>they</td>\n",
       "      <td>-1</td>\n",
       "      <td>Reucassel</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>Debnam</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Craig_Reucassel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation-5</td>\n",
       "      <td>By this time, Karen Blixen had separated from ...</td>\n",
       "      <td>Later</td>\n",
       "      <td>-1</td>\n",
       "      <td>Finch Hatton</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>Beryl Markham</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Denys_Finch_Hatton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Pronoun  \\\n",
       "0  validation-1  He admitted making four trips to China and pla...    them   \n",
       "1  validation-2  Kathleen Nott was born in Camberwell, London. ...    They   \n",
       "2  validation-3  When she returns to her hotel room, a Liberian...   their   \n",
       "3  validation-4  On 19 March 2007, during a campaign appearance...    they   \n",
       "4  validation-5  By this time, Karen Blixen had separated from ...   Later   \n",
       "\n",
       "   Pronoun-offset                   A  A-offset  A-coref              B  \\\n",
       "0              -1  Jose de Venecia Jr        -1    False         Abalos   \n",
       "1              -1               Ellen        -1    False       Kathleen   \n",
       "2              -1     Jason Scott Lee        -1    False          Danny   \n",
       "3              -1           Reucassel        -1     True         Debnam   \n",
       "4              -1        Finch Hatton        -1    False  Beryl Markham   \n",
       "\n",
       "   B-offset  B-coref                                                URL  \n",
       "0        -1    False  http://en.wikipedia.org/wiki/Commission_on_Ele...  \n",
       "1        -1     True         http://en.wikipedia.org/wiki/Kathleen_Nott  \n",
       "2        -1     True  http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...  \n",
       "3        -1    False       http://en.wikipedia.org/wiki/Craig_Reucassel  \n",
       "4        -1     True    http://en.wikipedia.org/wiki/Denys_Finch_Hatton  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_ntr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He admitted making four trips to China and playing golf there. He also admitted that ZTE officials, whom he says are his golf buddies, hosted and paid for the trips. Jose de Venecia III, son of House Speaker Jose de Venecia Jr, alleged that Abalos offered him US$10 million to withdraw his proposal on the NBN project. \n",
      " him 256\n",
      "52 him\n"
     ]
    }
   ],
   "source": [
    "row_idx = 0\n",
    "text = test_ntr_df.loc[row_idx, \"Text\"]\n",
    "pronoun = test_ntr_df.loc[row_idx, \"Pronoun\"]\n",
    "pronoun_offset = test_ntr_df.loc[row_idx, \"Pronoun-offset\"]\n",
    "word_idx = word_idx_from_char_offset(text, pronoun_offset)\n",
    "print(text, \"\\n\", pronoun, pronoun_offset)\n",
    "sent = word_tokenize(text)\n",
    "print(word_idx, sent[word_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
