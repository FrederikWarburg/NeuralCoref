{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Write method to present data\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frederikwarburg/anaconda3/envs/neuralcoref/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/coref-model-2018.02.05.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun  \\\n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her   \n",
       "1  development-2  He grew up in Evanston, Illinois the second ol...     His   \n",
       "2  development-3  He had been reelected to Congress, but resigne...     his   \n",
       "3  development-4  The current members of Crime have also perform...     his   \n",
       "4  development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...     She   \n",
       "\n",
       "   Pronoun-offset                  A  A-offset                B  B-offset  \\\n",
       "0             274     Cheryl Cassidy       191          Pauline       207   \n",
       "1             284          MacKenzie       228    Bernard Leach       251   \n",
       "2             265            Angeloz       173       De la Sota       246   \n",
       "3             321               Hell       174  Henry Rosenthal       336   \n",
       "4             437  Kitty Oppenheimer       219           Rivera       294   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1      http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3          http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4        http://en.wikipedia.org/wiki/Jessica_Rivera  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/gendered-pronoun-resolution/test_stage_1.tsv', sep = '\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He had been reelected to Congress, but resigned in 1990 to accept a post as Ambassador to Brazil. De la Sota again ran for governor of C*rdoba in 1991. Defeated by Governor Angeloz by over 15%, this latter setback was significant because it cost De la Sota much of his support within the Justicialist Party (which was flush with victory in the 1991 mid-terms), leading to President Carlos Menem 's endorsement of a separate party list in C*rdoba for the 1993 mid-term elections, and to De la Sota's failure to regain a seat in Congress.\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data['Text'][2]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('her boyfri',\n",
       " \"Cheryl Cassidy, Pauline's frie\",\n",
       " \"Pauline's friend and also a ye\")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data['Text'][0]\n",
    "text[274:274+10], text[191:191+30], text[207:207+30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(\n",
    "  document=text\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['top_spans', 'predicted_antecedents', 'document', 'clusters']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[9, 11], [15, 15], [52, 53], [60, 61], [64, 64], [78, 78]],\n",
       " [[4, 11], [25, 25]],\n",
       " [[36, 37], [57, 57], [70, 70], [82, 82]],\n",
       " [[39, 44], [82, 84]]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['Simon']\n",
      "antecedent\n",
      "['Simon', ',', 'Maggie']\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['he']\n",
      "antecedent\n",
      "['the', 'police', 'officer', 'girlfriend', 'of', 'Simon', ',', 'Maggie']\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['Simon', \"'s\"]\n",
      "antecedent\n",
      "['Simon']\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['her']\n",
      "antecedent\n",
      "['Phoebe', 'Thomas']\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['Simon', \"'s\"]\n",
      "antecedent\n",
      "['Simon', \"'s\"]\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['he']\n",
      "antecedent\n",
      "['Simon', \"'s\"]\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['her']\n",
      "antecedent\n",
      "['her']\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['him']\n",
      "antecedent\n",
      "['he']\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['her']\n",
      "antecedent\n",
      "['her']\n",
      "\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "new cluster\n",
      "pronoun\n",
      "['her', 'friend', 'Pauline']\n",
      "antecedent\n",
      "['Cheryl', 'Cassidy', ',', 'Pauline', \"'s\", 'friend']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "clusters = {}\n",
    "for i,top_span in enumerate(prediction['top_spans']):\n",
    "\n",
    "    for person in prediction['clusters']:\n",
    "        if top_span in person:\n",
    "            if prediction['predicted_antecedents'][i] != -1:\n",
    "\n",
    "                antecedent = prediction['top_spans'][i-1-prediction['predicted_antecedents'][i]]\n",
    "\n",
    "                print(\"pronoun\")\n",
    "                print(tokens[top_span[0]:top_span[1]+1])\n",
    "\n",
    "                print(\"antecedent\")\n",
    "                print(tokens[antecedent[0]:antecedent[1]+1])\n",
    "\n",
    "                print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster  0\n",
      "NOT MINUS 1\n",
      "['Simon', ',', 'Maggie']\n",
      "pronoun\n",
      "['Simon']\n",
      "antecedent\n",
      "['Simon', ',', 'Maggie']\n",
      "\n",
      "pronoun\n",
      "['Simon', \"'s\"]\n",
      "antecedent\n",
      "['Simon']\n",
      "\n",
      "pronoun\n",
      "['Simon', \"'s\"]\n",
      "antecedent\n",
      "['Simon', \"'s\"]\n",
      "\n",
      "pronoun\n",
      "['he']\n",
      "antecedent\n",
      "['Simon', \"'s\"]\n",
      "\n",
      "pronoun\n",
      "['him']\n",
      "antecedent\n",
      "['he']\n",
      "\n",
      "cluster  1\n",
      "NOT MINUS 1\n",
      "['the', 'police', 'officer', 'girlfriend', 'of', 'Simon', ',', 'Maggie']\n",
      "pronoun\n",
      "['he']\n",
      "antecedent\n",
      "['the', 'police', 'officer', 'girlfriend', 'of', 'Simon', ',', 'Maggie']\n",
      "\n",
      "cluster  2\n",
      "NOT MINUS 1\n",
      "['Phoebe', 'Thomas']\n",
      "pronoun\n",
      "['her']\n",
      "antecedent\n",
      "['Phoebe', 'Thomas']\n",
      "\n",
      "pronoun\n",
      "['her']\n",
      "antecedent\n",
      "['her']\n",
      "\n",
      "pronoun\n",
      "['her']\n",
      "antecedent\n",
      "['her']\n",
      "\n",
      "cluster  3\n",
      "NOT MINUS 1\n",
      "['Cheryl', 'Cassidy', ',', 'Pauline', \"'s\", 'friend']\n",
      "pronoun\n",
      "['her', 'friend', 'Pauline']\n",
      "antecedent\n",
      "['Cheryl', 'Cassidy', ',', 'Pauline', \"'s\", 'friend']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "clusters = {}\n",
    "for j,person in enumerate(prediction['clusters']):\n",
    "    print(\"cluster \", j)\n",
    "    for i,top_span in enumerate(prediction['top_spans']):\n",
    "\n",
    "        if top_span in person:\n",
    "            if prediction['predicted_antecedents'][i] != -1:\n",
    "\n",
    "                antecedent = prediction['top_spans'][i-1-prediction['predicted_antecedents'][i]]\n",
    "\n",
    "                print(\"pronoun\")\n",
    "                print(tokens[top_span[0]:top_span[1]+1])\n",
    "\n",
    "                print(\"antecedent\")\n",
    "                print(tokens[antecedent[0]:antecedent[1]+1])\n",
    "\n",
    "                print()\n",
    "            else:\n",
    "                print(\"NOT MINUS 1\")\n",
    "                print(tokens[top_span[0]:top_span[1]+1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "clusters = {}\n",
    "for j,person in enumerate(prediction['clusters']):\n",
    "\n",
    "    for i,top_span in enumerate(prediction['top_spans']):\n",
    "\n",
    "        if top_span in person:\n",
    "            if prediction['predicted_antecedents'][i] != -1:\n",
    "\n",
    "                antecedent = prediction['top_spans'][i-1-prediction['predicted_antecedents'][i]]\n",
    "\n",
    "                print(\"pronoun\")\n",
    "                print(tokens[top_span[0]:top_span[1]+1])\n",
    "\n",
    "                print(\"antecedent\")\n",
    "                print(tokens[antecedent[0]:antecedent[1]+1])\n",
    "\n",
    "                print()\n",
    "            else:\n",
    "                print(\"NOT MINUS 1\")\n",
    "                print(tokens[top_span[0]:top_span[1]+1])\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralcoref",
   "language": "python",
   "name": "neuralcoref"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
