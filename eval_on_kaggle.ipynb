{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frederikwarburg/anaconda3/envs/neuralcoref/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/coref-model-2018.02.05.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from utils import spans, get_cluster_num, get_span_from_offset\n",
    "from calculatescore import calculate_score, eval_gender, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun  \\\n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her   \n",
       "1  development-2  He grew up in Evanston, Illinois the second ol...     His   \n",
       "2  development-3  He had been reelected to Congress, but resigne...     his   \n",
       "3  development-4  The current members of Crime have also perform...     his   \n",
       "4  development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...     She   \n",
       "\n",
       "   Pronoun-offset                  A  A-offset                B  B-offset  \\\n",
       "0             274     Cheryl Cassidy       191          Pauline       207   \n",
       "1             284          MacKenzie       228    Bernard Leach       251   \n",
       "2             265            Angeloz       173       De la Sota       246   \n",
       "3             321               Hell       174  Henry Rosenthal       336   \n",
       "4             437  Kitty Oppenheimer       219           Rivera       294   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1      http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3          http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4        http://en.wikipedia.org/wiki/Jessica_Rivera  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/gendered-pronoun-resolution/test_stage_1.tsv', sep = '\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  /  2000\n",
      "10  /  2000\n",
      "20  /  2000\n",
      "30  /  2000\n",
      "40  /  2000\n",
      "50  /  2000\n",
      "60  /  2000\n",
      "70  /  2000\n",
      "80  /  2000\n",
      "90  /  2000\n",
      "100  /  2000\n",
      "110  /  2000\n",
      "120  /  2000\n",
      "130  /  2000\n",
      "140  /  2000\n",
      "150  /  2000\n",
      "160  /  2000\n",
      "170  /  2000\n",
      "180  /  2000\n",
      "190  /  2000\n",
      "200  /  2000\n",
      "210  /  2000\n",
      "220  /  2000\n",
      "230  /  2000\n",
      "240  /  2000\n",
      "250  /  2000\n",
      "260  /  2000\n",
      "270  /  2000\n",
      "280  /  2000\n",
      "290  /  2000\n",
      "300  /  2000\n",
      "310  /  2000\n",
      "320  /  2000\n",
      "330  /  2000\n",
      "340  /  2000\n",
      "350  /  2000\n",
      "360  /  2000\n",
      "370  /  2000\n",
      "380  /  2000\n",
      "390  /  2000\n",
      "400  /  2000\n",
      "410  /  2000\n",
      "420  /  2000\n",
      "430  /  2000\n",
      "440  /  2000\n",
      "450  /  2000\n",
      "460  /  2000\n",
      "470  /  2000\n",
      "480  /  2000\n",
      "490  /  2000\n",
      "500  /  2000\n",
      "510  /  2000\n",
      "520  /  2000\n",
      "530  /  2000\n",
      "540  /  2000\n",
      "550  /  2000\n",
      "560  /  2000\n",
      "570  /  2000\n",
      "580  /  2000\n",
      "590  /  2000\n",
      "600  /  2000\n",
      "610  /  2000\n",
      "620  /  2000\n",
      "630  /  2000\n",
      "640  /  2000\n",
      "650  /  2000\n",
      "660  /  2000\n",
      "670  /  2000\n",
      "680  /  2000\n",
      "690  /  2000\n",
      "700  /  2000\n",
      "710  /  2000\n",
      "720  /  2000\n",
      "730  /  2000\n",
      "740  /  2000\n",
      "750  /  2000\n",
      "760  /  2000\n",
      "770  /  2000\n",
      "780  /  2000\n",
      "790  /  2000\n",
      "800  /  2000\n",
      "810  /  2000\n",
      "820  /  2000\n",
      "830  /  2000\n",
      "840  /  2000\n",
      "850  /  2000\n",
      "860  /  2000\n",
      "870  /  2000\n",
      "880  /  2000\n",
      "890  /  2000\n",
      "900  /  2000\n",
      "910  /  2000\n",
      "920  /  2000\n",
      "930  /  2000\n",
      "940  /  2000\n",
      "950  /  2000\n",
      "960  /  2000\n",
      "970  /  2000\n",
      "980  /  2000\n",
      "990  /  2000\n",
      "1000  /  2000\n",
      "1010  /  2000\n",
      "1020  /  2000\n",
      "1030  /  2000\n",
      "1040  /  2000\n",
      "1050  /  2000\n",
      "1060  /  2000\n",
      "1070  /  2000\n",
      "1080  /  2000\n",
      "1090  /  2000\n",
      "1100  /  2000\n",
      "1110  /  2000\n",
      "1120  /  2000\n",
      "1130  /  2000\n",
      "1140  /  2000\n",
      "1150  /  2000\n",
      "1160  /  2000\n",
      "1170  /  2000\n",
      "1180  /  2000\n",
      "1190  /  2000\n",
      "1200  /  2000\n",
      "1210  /  2000\n",
      "1220  /  2000\n",
      "1230  /  2000\n",
      "1240  /  2000\n",
      "1250  /  2000\n",
      "1260  /  2000\n",
      "1270  /  2000\n",
      "1280  /  2000\n",
      "1290  /  2000\n",
      "1300  /  2000\n",
      "1310  /  2000\n",
      "1320  /  2000\n",
      "1330  /  2000\n",
      "1340  /  2000\n",
      "1350  /  2000\n",
      "1360  /  2000\n",
      "1370  /  2000\n",
      "1380  /  2000\n",
      "1390  /  2000\n",
      "1400  /  2000\n",
      "1410  /  2000\n",
      "1420  /  2000\n",
      "1430  /  2000\n",
      "1440  /  2000\n",
      "1450  /  2000\n",
      "1460  /  2000\n",
      "1470  /  2000\n",
      "1480  /  2000\n",
      "1490  /  2000\n",
      "1500  /  2000\n",
      "1510  /  2000\n",
      "1520  /  2000\n",
      "1530  /  2000\n",
      "1540  /  2000\n",
      "1550  /  2000\n",
      "1560  /  2000\n",
      "1570  /  2000\n",
      "1580  /  2000\n",
      "1590  /  2000\n",
      "1600  /  2000\n",
      "1610  /  2000\n",
      "1620  /  2000\n",
      "1630  /  2000\n",
      "1640  /  2000\n",
      "1650  /  2000\n",
      "1660  /  2000\n",
      "1670  /  2000\n",
      "1680  /  2000\n",
      "1690  /  2000\n",
      "1700  /  2000\n",
      "1710  /  2000\n",
      "1720  /  2000\n",
      "1730  /  2000\n",
      "1740  /  2000\n",
      "1750  /  2000\n",
      "1760  /  2000\n",
      "1770  /  2000\n",
      "1780  /  2000\n",
      "1790  /  2000\n",
      "1800  /  2000\n",
      "1810  /  2000\n",
      "1820  /  2000\n",
      "1830  /  2000\n",
      "1840  /  2000\n",
      "1850  /  2000\n",
      "1860  /  2000\n",
      "1870  /  2000\n",
      "1880  /  2000\n",
      "1890  /  2000\n",
      "1900  /  2000\n",
      "1910  /  2000\n",
      "1920  /  2000\n",
      "1930  /  2000\n",
      "1940  /  2000\n",
      "1950  /  2000\n",
      "1960  /  2000\n",
      "1970  /  2000\n",
      "1980  /  2000\n",
      "1990  /  2000\n"
     ]
    }
   ],
   "source": [
    "# NOTE THAT THIS TAKES A LONG TIME > 30 min\n",
    "\n",
    "results = []\n",
    "for index in range(len(data['Text'])):\n",
    "    \n",
    "    text = data['Text'][index]\n",
    "    prediction = predictor.predict(\n",
    "      document=text\n",
    "    )\n",
    "\n",
    "    pronoun_span = get_span_from_offset(text, data['Pronoun-offset'][index])\n",
    "    A_span = get_span_from_offset(text, data['A-offset'][index])\n",
    "    B_span = get_span_from_offset(text, data['B-offset'][index])\n",
    "\n",
    "    pronoun_cluster_num = get_cluster_num(pronoun_span, prediction)\n",
    "    A_cluster_num = get_cluster_num(A_span, prediction)\n",
    "    B_cluster_num = get_cluster_num(B_span, prediction)\n",
    "\n",
    "    A, B, N = 0, 0, 0\n",
    "    for pronoun_pred in pronoun_cluster_num:\n",
    "        if pronoun_pred in A_cluster_num: A = 1 \n",
    "        if pronoun_pred in B_cluster_num: B = 1 \n",
    "\n",
    "    if A == 0 and B == 0: N = 1\n",
    "    \n",
    "    results.append([A, B, N])\n",
    "    \n",
    "    if index % 10 == 0:\n",
    "        print(index, \" / \", len(data['Text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  NEITHER\n",
       "0  0  0        1\n",
       "1  0  0        1\n",
       "2  0  0        1\n",
       "3  0  0        1\n",
       "4  0  0        1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random guess\n",
    "predictions = pd.DataFrame(results, columns=['A','B','NEITHER'])\n",
    "predictions.to_csv('data/predictions_allen_default1.csv')\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.00977982080348"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score('data/right_answers.csv','data/predictions_allen_default1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61586314 0.67114094 0.15904366] [0.45308924 0.43243243 0.76119403] [0.52208306 0.52596976 0.26311264]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = evaluate('data/right_answers.csv', 'data/predictions_allen_default1.csv')\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision: A = 0.6192, B = 0.6706, Neither = 0.1735\n",
      "Male recall: A = 0.5159817351598174, B = 0.5010893246187363, Neither = 0.6990291262135923\n",
      "Male F1: A = 0.5629, B = 0.5736, Neither = 0.278 \n",
      "\n",
      "Female precision: A = 0.6115107913669064, B = 0.6719367588932806, Neither = 0.1480804387568556\n",
      "Female recall: A = 0.38990825688073394, B = 0.3648068669527897, Neither = 0.826530612244898\n",
      "Female F1: A = 0.4762, B = 0.4729, Neither = 0.2512\n"
     ]
    }
   ],
   "source": [
    "# Gold path\n",
    "path_gold = 'data/right_answers.csv'\n",
    "\n",
    "# Path full data #\n",
    "path_full = 'data/gendered-pronoun-resolution/test_stage_1.tsv'\n",
    "df = pd.read_csv(path_full, sep = '\\t', index_col = 0) \n",
    "\n",
    "# Create predictions #\n",
    "predictions = pd.DataFrame(results, columns=['A','B','NEITHER'], index = list(df.index))\n",
    "predictions.to_csv('data/predictions_allen_default2.csv')\n",
    "path_pred = 'data/predictions_allen_default2.csv'\n",
    "\n",
    "male_sc, female_sc = eval_gender(path_gold, path_pred, path_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralcoref",
   "language": "python",
   "name": "neuralcoref"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
