{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frederikwarburg/anaconda3/envs/neuralcoref/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/coref-model-2018.02.05.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from calculatescore import calculate_score, eval_gender, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>Between the years 1979-1981, River won four lo...</td>\n",
       "      <td>him</td>\n",
       "      <td>430</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>353</td>\n",
       "      <td>True</td>\n",
       "      <td>Alfredo Di St*fano</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>Though his emigration from the country has aff...</td>\n",
       "      <td>He</td>\n",
       "      <td>312</td>\n",
       "      <td>Ali Aladhadh</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>Saddam</td>\n",
       "      <td>295</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test-4</td>\n",
       "      <td>At the trial, Pisciotta said: ``Those who have...</td>\n",
       "      <td>his</td>\n",
       "      <td>526</td>\n",
       "      <td>Alliata</td>\n",
       "      <td>377</td>\n",
       "      <td>False</td>\n",
       "      <td>Pisciotta</td>\n",
       "      <td>536</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-5</td>\n",
       "      <td>It is about a pair of United States Navy shore...</td>\n",
       "      <td>his</td>\n",
       "      <td>406</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>421</td>\n",
       "      <td>True</td>\n",
       "      <td>Rock Reilly</td>\n",
       "      <td>559</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Chasers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Text Pronoun  \\\n",
       "0  test-1  Upon their acceptance into the Kontinental Hoc...     His   \n",
       "1  test-2  Between the years 1979-1981, River won four lo...     him   \n",
       "2  test-3  Though his emigration from the country has aff...      He   \n",
       "3  test-4  At the trial, Pisciotta said: ``Those who have...     his   \n",
       "4  test-5  It is about a pair of United States Navy shore...     his   \n",
       "\n",
       "   Pronoun-offset             A  A-offset  A-coref                   B  \\\n",
       "0             383     Bob Suter       352    False              Dehner   \n",
       "1             430        Alonso       353     True  Alfredo Di St*fano   \n",
       "2             312  Ali Aladhadh       256     True              Saddam   \n",
       "3             526       Alliata       377    False           Pisciotta   \n",
       "4             406         Eddie       421     True         Rock Reilly   \n",
       "\n",
       "   B-offset  B-coref                                             URL  \n",
       "0       366     True      http://en.wikipedia.org/wiki/Jeremy_Dehner  \n",
       "1       390    False    http://en.wikipedia.org/wiki/Norberto_Alonso  \n",
       "2       295    False           http://en.wikipedia.org/wiki/Aladhadh  \n",
       "3       536     True  http://en.wikipedia.org/wiki/Gaspare_Pisciotta  \n",
       "4       559    False            http://en.wikipedia.org/wiki/Chasers  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/gap/gap-test.tsv', sep = '\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered the antecedent_indices key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[1, 1], [8, 8], [12, 12]],\n",
       " [[19, 20], [39, 40]],\n",
       " [[26, 28], [57, 59]],\n",
       " [[57, 58], [61, 61], [65, 65], [69, 69]]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text = 'This is the first sentence. This is the second sentence.'\n",
    "prediction = predictor.predict(\n",
    "  document=text\n",
    ")\n",
    "prediction['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  /  2000\n",
      "10  /  2000\n",
      "20  /  2000\n",
      "30  /  2000\n",
      "40  /  2000\n",
      "50  /  2000\n",
      "60  /  2000\n",
      "70  /  2000\n",
      "80  /  2000\n",
      "90  /  2000\n",
      "100  /  2000\n",
      "110  /  2000\n",
      "120  /  2000\n",
      "130  /  2000\n",
      "140  /  2000\n",
      "150  /  2000\n",
      "160  /  2000\n",
      "170  /  2000\n",
      "180  /  2000\n",
      "190  /  2000\n",
      "200  /  2000\n",
      "210  /  2000\n",
      "220  /  2000\n",
      "230  /  2000\n",
      "240  /  2000\n",
      "250  /  2000\n",
      "260  /  2000\n",
      "270  /  2000\n",
      "280  /  2000\n",
      "290  /  2000\n",
      "300  /  2000\n",
      "310  /  2000\n",
      "320  /  2000\n",
      "330  /  2000\n",
      "340  /  2000\n",
      "350  /  2000\n",
      "360  /  2000\n",
      "370  /  2000\n",
      "380  /  2000\n",
      "390  /  2000\n",
      "400  /  2000\n",
      "410  /  2000\n",
      "420  /  2000\n",
      "430  /  2000\n",
      "440  /  2000\n",
      "450  /  2000\n",
      "460  /  2000\n",
      "470  /  2000\n",
      "480  /  2000\n",
      "490  /  2000\n",
      "500  /  2000\n",
      "510  /  2000\n",
      "520  /  2000\n",
      "530  /  2000\n",
      "540  /  2000\n",
      "550  /  2000\n",
      "560  /  2000\n",
      "570  /  2000\n",
      "580  /  2000\n",
      "590  /  2000\n",
      "600  /  2000\n",
      "610  /  2000\n",
      "620  /  2000\n",
      "630  /  2000\n",
      "640  /  2000\n",
      "650  /  2000\n",
      "660  /  2000\n",
      "670  /  2000\n",
      "680  /  2000\n",
      "690  /  2000\n",
      "700  /  2000\n",
      "710  /  2000\n",
      "720  /  2000\n",
      "730  /  2000\n",
      "740  /  2000\n",
      "750  /  2000\n",
      "760  /  2000\n",
      "770  /  2000\n",
      "780  /  2000\n",
      "790  /  2000\n",
      "800  /  2000\n",
      "810  /  2000\n",
      "820  /  2000\n",
      "830  /  2000\n",
      "840  /  2000\n",
      "850  /  2000\n",
      "860  /  2000\n",
      "870  /  2000\n",
      "880  /  2000\n",
      "890  /  2000\n",
      "900  /  2000\n",
      "910  /  2000\n",
      "920  /  2000\n",
      "930  /  2000\n",
      "940  /  2000\n",
      "950  /  2000\n",
      "960  /  2000\n",
      "970  /  2000\n",
      "980  /  2000\n",
      "990  /  2000\n",
      "1000  /  2000\n",
      "1010  /  2000\n",
      "1020  /  2000\n",
      "1030  /  2000\n",
      "1040  /  2000\n",
      "1050  /  2000\n",
      "1060  /  2000\n",
      "1070  /  2000\n",
      "1080  /  2000\n",
      "1090  /  2000\n",
      "1100  /  2000\n",
      "1110  /  2000\n",
      "1120  /  2000\n",
      "1130  /  2000\n",
      "1140  /  2000\n",
      "1150  /  2000\n",
      "1160  /  2000\n",
      "1170  /  2000\n",
      "1180  /  2000\n",
      "1190  /  2000\n",
      "1200  /  2000\n",
      "1210  /  2000\n",
      "1220  /  2000\n",
      "1230  /  2000\n",
      "1240  /  2000\n",
      "1250  /  2000\n",
      "1260  /  2000\n",
      "1270  /  2000\n",
      "1280  /  2000\n",
      "1290  /  2000\n",
      "1300  /  2000\n",
      "1310  /  2000\n",
      "1320  /  2000\n",
      "1330  /  2000\n",
      "1340  /  2000\n",
      "1350  /  2000\n",
      "1360  /  2000\n",
      "1370  /  2000\n",
      "1380  /  2000\n",
      "1390  /  2000\n",
      "1400  /  2000\n",
      "1410  /  2000\n",
      "1420  /  2000\n",
      "1430  /  2000\n",
      "1440  /  2000\n",
      "1450  /  2000\n",
      "1460  /  2000\n",
      "1470  /  2000\n",
      "1480  /  2000\n",
      "1490  /  2000\n",
      "1500  /  2000\n",
      "1510  /  2000\n",
      "1520  /  2000\n",
      "1530  /  2000\n",
      "1540  /  2000\n",
      "1550  /  2000\n",
      "1560  /  2000\n",
      "1570  /  2000\n",
      "1580  /  2000\n",
      "1590  /  2000\n",
      "1600  /  2000\n",
      "1610  /  2000\n",
      "1620  /  2000\n",
      "1630  /  2000\n",
      "1640  /  2000\n",
      "1650  /  2000\n",
      "1660  /  2000\n",
      "1670  /  2000\n",
      "1680  /  2000\n",
      "1690  /  2000\n",
      "1700  /  2000\n",
      "1710  /  2000\n",
      "1720  /  2000\n",
      "1730  /  2000\n",
      "1740  /  2000\n",
      "1750  /  2000\n",
      "1760  /  2000\n",
      "1770  /  2000\n",
      "1780  /  2000\n",
      "1790  /  2000\n",
      "1800  /  2000\n",
      "1810  /  2000\n",
      "1820  /  2000\n",
      "1830  /  2000\n",
      "1840  /  2000\n",
      "1850  /  2000\n",
      "1860  /  2000\n",
      "1870  /  2000\n",
      "1880  /  2000\n",
      "1890  /  2000\n",
      "1900  /  2000\n",
      "1910  /  2000\n",
      "1920  /  2000\n",
      "1930  /  2000\n",
      "1940  /  2000\n",
      "1950  /  2000\n",
      "1960  /  2000\n",
      "1970  /  2000\n",
      "1980  /  2000\n",
      "1990  /  2000\n"
     ]
    }
   ],
   "source": [
    "# NOTE THAT THIS TAKES A LONG TIME > 30 min\n",
    "\n",
    "results = []\n",
    "for index in range(len(data['Text'])):\n",
    "    \n",
    "    text = data['Text'][index]\n",
    "    prediction = predictor.predict(\n",
    "      document=text\n",
    "    )\n",
    "\n",
    "    pronoun_span = get_span_from_offset(text, data['Pronoun-offset'][index])\n",
    "    A_span = get_span_from_offset(text, data['A-offset'][index])\n",
    "    B_span = get_span_from_offset(text, data['B-offset'][index])\n",
    "\n",
    "    pronoun_cluster_num = get_cluster_num(pronoun_span, prediction)\n",
    "    A_cluster_num = get_cluster_num(A_span, prediction)\n",
    "    B_cluster_num = get_cluster_num(B_span, prediction)\n",
    "\n",
    "    A, B, N = 0, 0, 0\n",
    "    for pronoun_pred in pronoun_cluster_num:\n",
    "        if pronoun_pred in A_cluster_num: A = 1 \n",
    "        if pronoun_pred in B_cluster_num: B = 1 \n",
    "\n",
    "    if A == 0 and B == 0: N = 1\n",
    "    \n",
    "    results.append([A, B, N])\n",
    "    \n",
    "    if index % 10 == 0:\n",
    "        print(index, \" / \", len(data['Text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  NEITHER\n",
       "0  0  0        1\n",
       "1  1  0        0\n",
       "2  0  1        0\n",
       "3  0  0        1\n",
       "4  1  0        0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random guess\n",
    "predictions = pd.DataFrame(results, columns=['A','B','NEITHER'])\n",
    "predictions.to_csv('data/predictions_allen_default1.csv')\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.476225184070334"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score('data/right_answers.csv','data/predictions_allen_default1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43140244 0.47359736 0.10805085] [0.32379863 0.31027027 0.50746269] [0.36993464 0.37491835 0.17816594]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = evaluate('data/right_answers.csv', 'data/predictions_allen_default1.csv')\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision: A = 0.4281, B = 0.4573, Neither = 0.1032\n",
      "Male recall: A = 0.2990867579908676, B = 0.32679738562091504, Neither = 0.46601941747572817\n",
      "Male F1: A = 0.3522, B = 0.3812, Neither = 0.169 \n",
      "\n",
      "Female precision: A = 0.4342857142857143, B = 0.49280575539568344, Neither = 0.1127348643006263\n",
      "Female recall: A = 0.3486238532110092, B = 0.2939914163090129, Neither = 0.5510204081632653\n",
      "Female F1: A = 0.3868, B = 0.3683, Neither = 0.1872\n"
     ]
    }
   ],
   "source": [
    "# Gold path\n",
    "path_gold = 'data/right_answers.csv'\n",
    "\n",
    "# Path full data #\n",
    "path_full = 'data/gendered-pronoun-resolution/test_stage_1.tsv'\n",
    "df = pd.read_csv(path_full, sep = '\\t', index_col = 0) \n",
    "\n",
    "# Create predictions #\n",
    "predictions = pd.DataFrame(results, columns=['A','B','NEITHER'], index = list(df.index))\n",
    "predictions.to_csv('data/predictions_allen_default2.csv')\n",
    "path_pred = 'data/predictions_allen_default2.csv'\n",
    "\n",
    "male_sc, female_sc = eval_gender(path_gold, path_pred, path_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralcoref",
   "language": "python",
   "name": "neuralcoref"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
